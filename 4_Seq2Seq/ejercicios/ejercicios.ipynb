{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ejercicios",
      "provenance": [],
      "collapsed_sections": [
        "8Ke8ufJfxrUz",
        "vAGmz5MuAvRA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/institutohumai/cursos-python/blob/master/NLP/4_Seq2Seq/ejercicios/ejercicios.ipynb\"> <img src='https://colab.research.google.com/assets/colab-badge.svg' /> </a>"
      ],
      "metadata": {
        "id": "OOeOzi93GK1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio Clase 4"
      ],
      "metadata": {
        "id": "xYoP47ig-o01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este notebook modificaremos el encoder del modelo de traducción automática visto en la clase para utilizar una RNN bidireccional. Al igual que en el modelo anterior, usamos un GRU de dos capas, sin embargo ahora la haremos bidireccional. Con un RNN bidireccional, tenemos dos RNN en cada capa. Un *RNN hacia adelante* que repasa los embedding de la oración de izquierda a derecha (que se muestra a continuación en verde), y un *RNN hacia atrás* que repasa los embedding de la oración de derecha a izquierda (verde azulado). Todo lo que necesitamos hacer en el código es establecer `bidirectional = True` y luego pasar los embedding de la oración al RNN como antes.\n",
        "\n",
        "![](https://i.imgur.com/bdUnvj9.png)\n",
        "\n",
        "Ahora tenemos:\n",
        "\n",
        "$$\\begin{align*}\n",
        "h_t^\\rightarrow &= \\text{EncoderGRU}^\\rightarrow(e(x_t^\\rightarrow),h_{t-1}^\\rightarrow)\\\\\n",
        "h_t^\\leftarrow &= \\text{EncoderGRU}^\\leftarrow(e(x_t^\\leftarrow),h_{t-1}^\\leftarrow)\n",
        "\\end{align*}$$\n",
        "\n",
        "Donde $x_0^\\rightarrow = \\text{<sos>}, x_1^\\rightarrow = \\text{guten}$ and $x_0^\\leftarrow = \\text{<eos>}, x_1^\\leftarrow = \\text{morgen}$.\n",
        "\n",
        "Como antes, solo pasamos una entrada(`embedded`) al RNN, que le dice a PyTorch que inicialice los estados ocultos iniciales hacia adelante y hacia atrás ($ h_0 ^ \\rightarrow $ y $ h_0 ^ \\leftarrow $, respectivamente) como un tensor de todos los ceros. También obtendremos dos vectores de contexto, uno del RNN hacia adelante después de haber visto la última palabra en la oración, $ z ^ \\rightarrow = h_T ^ \\rightarrow $, y uno del RNN hacia atrás después de haber visto la primera palabra en la oración, $ z ^ \\leftarrow = h_T ^ \\leftarrow $.\n",
        "\n",
        "El RNN devuelve `outputs` y `hidden`.\n",
        "\n",
        "`outputs` es de tamaño `[longitud de la oración de origen, tamaño de lote, (dimensión de variables ocultas)x(numero de direcciones)]` donde los primeros ` num_hiddens` elementos en el tercer eje son los estados ocultos de la capa superior hacia adelante RNN, y los últimos `num_hiddens ` elementos son estados ocultos de la capa superior hacia atrás RNN. Podemos pensar en el tercer eje como los estados ocultos hacia adelante y hacia atrás concatenados entre sí, es decir, $ h_1 = [h_1 ^ \\rightarrow; h_{T} ^ \\leftarrow] $, $ h_2 = [h_2 ^ \\rightarrow; h_{T-1} ^ \\leftarrow] $ y podemos denotar todos los estados ocultos del encoder (hacia adelante y hacia atrás concatenados juntos) como $ H = \\{h_1, h_2, ..., h_T \\} $. \n",
        "\n",
        "`hidden` es de tamaño **[número de capas * número de direcciones, tamaño de lote, dimensión de variables ocultas]**, donde `hidden[- 2,:,:]` entregaría el estado oculto de la capa superior de la RNN hacia adelante después del paso de tiempo final (es decir, después de haber visto la última palabra en la oración), `hidden[- 1,:,: ]` entregaría el estado oculto de la capa superior de la RNN hacia atrás después del paso de tiempo final (es decir, después de haber visto la primera palabra en la oración) y así sucesivamente.\n",
        "\n",
        "Como el decoder no es bidireccional, solo necesitaremos un vector de contexto $z$, y actualmente tenemos dos versiones, uno hacia adelante y uno hacia atrás ($ z ^ \\rightarrow = h_T ^ \\rightarrow $ y $ z ^ \\leftarrow = h_T ^ \\leftarrow $, respectivamente). Resolvemos esto concatenando los dos vectores de contexto juntos, pasándolos a través de una capa lineal, $ g $, y aplicando la función de activación $ \\tanh $. \n",
        "\n",
        "$$z=\\tanh(g(h_T^\\rightarrow, h_T^\\leftarrow)) = \\tanh(g(z^\\rightarrow, z^\\leftarrow)) = s_0$$\n",
        "\n",
        "Lo mismo sucede con los estados ocultos que pasamos para usar como estado inicial $s_0$ en el decoder. Aquí también definiremos una capa lineal para transformarlos, pero teniendo en cuenta que tendremos que hacerlo capa por capa.\n"
      ],
      "metadata": {
        "id": "BErsixMqjGVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 1\n",
        "\n",
        "Teniendo en cuenta las cuestiones de implementación mencionadas en la introducción, modificar el Encoder y el Decoder planteados en la clase 4 para que se procese a la oración de origen con una RNN bidireccional."
      ],
      "metadata": {
        "id": "iB6u2aGeCwOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inserte su código aquí"
      ],
      "metadata": {
        "id": "Xz6fOFVxDofS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 2 \n",
        "\n",
        "Cree un modelo Seq2Seq que utilice el encoder y el decoder del ejercicio anterior. Entrénelo sobre el dataset inglés-español utilizado en clase"
      ],
      "metadata": {
        "id": "PxAzReBPDuto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# inserte su código aquí"
      ],
      "metadata": {
        "id": "2EW-4LPkGnfP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}